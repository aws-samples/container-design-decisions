{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-container-design-decisions","title":"Welcome to Container Design Decisions","text":"<p>The repository offers a framework that helps a broad range of technical practitioners to make informed decisions to adpot container technologies.  - properly understand and evaluate the entirety of the technical problem space when designing or transforming a containers solution,   - for each relevant technical domain, understood the available options and associated trade-offs  - describe and document each architectural decision, its context, and its consequences in a clear and standard format. </p>"},{"location":"#contributing","title":"Contributing","text":"<p>See CONTRIBUTING for more information.</p> <p>See Code of Conduct for more information.</p>"},{"location":"#license","title":"License","text":"<p>This library is licensed under the MIT-0 License. See the LICENSE file.</p>"},{"location":"EKS/Operations/ADR-EKS-OPS-07000-OPERATING-MODEL/","title":"Designing Operating Model for Container Platform","text":"<p>Designing an operating model for a container platform involves evaluating multiple options to meet specific organizational needs regarding operational excellence, constraints, competency, control and security, consistency, cost management, and productivity.</p>"},{"location":"EKS/Operations/ADR-EKS-OPS-07000-OPERATING-MODEL/#decision-drivers","title":"Decision Drivers","text":"<ul> <li>Operational Excellence: Ensuring efficient management and maintenance of the container platform.</li> <li>Constraints: Identifying limitations and challenges in the current operational model.</li> <li>Competency: Assessing the skill level and experience of the team with container technologies and DevOps practices.</li> <li>Control and Security: Protecting the infrastructure and data from vulnerabilities and breaches.</li> <li>Consistency: Achieving uniformity in processes and practices across teams.</li> <li>Cost Management: Balancing performance and resource allocation against cost.</li> <li>Productivity: Enhancing the efficiency and output of development teams.</li> </ul>"},{"location":"EKS/Operations/ADR-EKS-OPS-07000-OPERATING-MODEL/#considered-options","title":"Considered Options","text":"<ul> <li>Centralized Provisioning</li> <li>Platform-enabled Golden Path</li> <li>Embedded DevOps</li> <li>Decentralized DevOps</li> </ul>"},{"location":"EKS/Operations/ADR-EKS-OPS-07000-OPERATING-MODEL/#pros-and-cons-of-the-options","title":"Pros and Cons of the Options","text":""},{"location":"EKS/Operations/ADR-EKS-OPS-07000-OPERATING-MODEL/#centralized-provisioning","title":"Centralized Provisioning","text":"<p>Description: In a centralized provisioning model, a dedicated team is responsible for architecting, deploying, and managing the infrastructure. This model provides central control over resource provisioning but may introduce bottlenecks and slower deployment cycles.</p> <ul> <li>Good, because it ensures consistency and central control over resources.</li> <li>Good, because it allows specialized teams to handle complex infrastructure tasks.</li> <li>Neutral, because it may lead to a backlog of requests, slowing down development.</li> <li>Bad, because it can reduce the autonomy of development teams, leading to frustration.</li> <li>Bad, because it may become a single point of failure if the central team encounters issues.</li> </ul>"},{"location":"EKS/Operations/ADR-EKS-OPS-07000-OPERATING-MODEL/#platform-enabled-golden-path","title":"Platform-enabled Golden Path","text":"<p>Description: This model offers a predefined set of best practices and tools, allowing for customization while maintaining consistency. It strikes a balance between flexibility and standardization.</p> <ul> <li>Good, because it promotes best practices and reduces the risk of misconfigurations.</li> <li>Good, because it enables rapid onboarding of new teams and projects.</li> <li>Neutral, because it requires significant effort to develop and maintain the golden path.</li> <li>Bad, because it may limit flexibility for teams with unique requirements.</li> <li>Bad, because deviations from the golden path might not be well-supported.</li> </ul>"},{"location":"EKS/Operations/ADR-EKS-OPS-07000-OPERATING-MODEL/#embedded-devops","title":"Embedded DevOps","text":"<p>Description: Embedded DevOps places DevOps engineers within individual development teams, ensuring close collaboration and tailored support for each team's needs.</p> <ul> <li>Good, because it fosters close collaboration between developers and operations.</li> <li>Good, because it allows for tailored solutions that meet the specific needs of each team.</li> <li>Neutral, because it requires more DevOps resources, which can be costly.</li> <li>Bad, because it may lead to inconsistencies across the organization.</li> <li>Bad, because knowledge and expertise can become siloed within individual teams.</li> </ul>"},{"location":"EKS/Operations/ADR-EKS-OPS-07000-OPERATING-MODEL/#decentralized-devops","title":"Decentralized DevOps","text":"<p>Description: This model gives development teams full ownership and responsibility for defining and managing their infrastructure and pipelines, offering maximum autonomy and flexibility.</p> <ul> <li>Good, because it maximizes team autonomy and enables rapid innovation.</li> <li>Good, because it allows teams to tailor their processes and tools to best fit their specific needs.</li> <li>Neutral, because it requires strong governance and communication to ensure consistency.</li> <li>Bad, because it can lead to fragmentation and inconsistency, making it harder to maintain standards.</li> <li>Bad, because it may result in duplicated efforts and increased overhead as each team develops their own solutions.</li> </ul>"},{"location":"EKS/Operations/ADR-EKS-OPS-07000-OPERATING-MODEL/#resources","title":"Resources","text":"<ol> <li>How organizations are modernizing for cloud operations</li> <li>Modernizing operations in the AWS Cloud</li> <li>Strategy for modernizing applications in the AWS Cloud</li> </ol>"},{"location":"EKS/Operations/ADR-EKS-OPS-07000-OPERATING-MODEL/#discovery-questions","title":"Discovery Questions","text":"<ol> <li>Priorities and Requirements:</li> <li>What are the most important goals you want to achieve with your container platform (e.g., faster deployment, better security, reduced costs)?</li> <li> <p>Are there any specific requirements or constraints that must be met (e.g., regulatory compliance, integration with existing systems)?</p> </li> <li> <p>Constraints:</p> </li> <li>What limitations or challenges do you face in your current operational model (e.g., resource bottlenecks, lack of automation)?</li> <li> <p>How do you manage dependencies and coordination between different teams or departments?</p> </li> <li> <p>Competency:</p> </li> <li>What is the current skill level and experience of your team with container technologies and DevOps practices?</li> <li> <p>How comfortable are your teams with managing their own infrastructure versus relying on a central team?</p> </li> <li> <p>Control and Security:</p> </li> <li>What are your primary security concerns related to container management and orchestration?</li> <li> <p>How do you currently handle security policies and compliance requirements across different teams?</p> </li> <li> <p>Consistency:</p> </li> <li>How important is it for your organization to have consistent processes and practices across all teams?</li> <li> <p>What measures do you have in place to ensure uniformity in your operations?</p> </li> <li> <p>Cost Management:</p> </li> <li>What is your budget for managing and maintaining your container platform, and how do you plan to control costs?</li> <li> <p>How do you currently allocate resources and manage cost efficiency across your teams?</p> </li> <li> <p>Productivity:</p> </li> <li>How do you measure the productivity of your development teams?</li> <li> <p>What tools and practices do you use to enhance the efficiency and output of your teams?</p> </li> <li> <p>Future Plans:</p> </li> <li>What are your plans for scaling your container platform, and how do you envision the growth of your DevOps practices?</li> <li>How do you plan to stay updated with the latest technologies and best practices in container management and orchestration?</li> </ol>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/","title":"Designing a Strategy to Deploy Kubernetes Cluster for Multi-Tenancy","text":"<p>Deploying a Kubernetes (k8s) cluster for multi-tenancy involves choosing an appropriate strategy to manage multiple tenants efficiently while ensuring operational excellence, security, performance, cost management, and reliability.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#decision-drivers","title":"Decision Drivers","text":"<ul> <li>Operational Excellence: The ease of managing and maintaining the clusters.</li> <li>Security: Ensuring strong isolation and security between tenants.</li> <li>Performance: Maintaining high performance and resource efficiency.</li> <li>Cost Management: Minimizing costs associated with infrastructure and operations.</li> <li>Reliability: Ensuring high availability and resilience of the clusters.</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#considered-options","title":"Considered Options","text":"<ul> <li>Namespace per tenant</li> <li>Virtual Cluster per tenant</li> <li>Cluster per tenant</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#pros-and-cons-of-the-options","title":"Pros and Cons of the Options","text":""},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#namespace-per-tenant","title":"Namespace per Tenant","text":"<p>Description: Each tenant is assigned a separate namespace within a single Kubernetes cluster.</p> <p>Pros:</p> <ul> <li>Cost-Efficient: Sharing a single cluster reduces infrastructure costs. You can mix different application profiles. For example, combine applications with spiky workloads with those that have steady resource demands. This allows resources to be used effectively when the spiky workloads are idle.</li> <li>Simpler Management: Easier to manage and monitor compared to maintaining multiple clusters,as all tenants share the same control plane.</li> <li>Resource Quotas and Limits: Kubernetes allows setting resource quotas and limits at the namespace level, ensuring fair resource distribution.</li> </ul> <p>Cons:</p> <ul> <li>Security Risks: Potential for insufficient isolation, which can lead to security risks if not properly managed.</li> <li>Performance Contention: Resource contention can occur if resource limits and quotas are not correctly configured.</li> <li>Reliability Large blast radius for outages, planned or unplanned</li> <li>Operational Excellence Some cluster-level resources and controllers may not be a good fit.</li> </ul> <p>Considerations:</p> <ul> <li>Security risks can be managed through Kubernetes RBAC and network policies, but strong isolation requires careful configuration.</li> <li>Requires careful configuration of network policies to isolate network traffic between namespaces.</li> <li>Consider 3rd party tools for cost charge back/show back </li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#virtual-cluster-per-tenant","title":"Virtual Cluster per Tenant","text":"<p>Description: Each tenant gets a virtual cluster. Virtual clusters are a Kubernetes concept that enables isolated clusters to be run within a single physical Kubernetes cluster. Each cluster has its own API server, often achieved using solutions like Kiosk or vCluster.</p> <p>Pros:</p> <ul> <li>Better Isolation for development:  Compared to namespaces, virtual clusters offer superior isolation from a control plane perspective, as each virtual cluster operates with its own dedicated control plane. Virtual clusters can be spun up and down as needed, providing a fresh environment for development. </li> <li>Granular Resource Control: Virtual clusters can help in optimizing resource utilization by allowing dynamic allocation of resources based on demand. </li> <li>Improved Security: Virtual clusters provide an additional layer of security by isolating workloads at the control plane level. It is possible to implement more granular access control policies. Each virtual cluster can have its own set of RBAC (Role-Based Access Control) rules, ensuring that only authorized users have access to specific resources and operations within their cluster\u200b </li> <li>Operational Excellence quicky provision Dev/UAT/PreProd environments with virtual clusters. Tenants can be admins inside their virtual cluster without being admin in the underlying cluster.</li> </ul> <p>Cons:</p> <ul> <li>Operational Overhead: More complex to set up and manage than namespace isolation.</li> <li>Performance Overhead: Potential performance overhead due to the additional layer of virtualization. </li> </ul> <p>Considerations:</p> <ul> <li>It still shares the same control plane, so control plane resource contention is possible.</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#cluster-per-tenant","title":"Cluster per Tenant","text":"<p>Description: The most secure way to run Silo workloads on EKS is to create a distinct EKS cluster for each tenant. In such a design, even a tenant that runs privileged containers and has access to the hosts cannot impact other tenants.</p> <p>Pros:</p> <ul> <li>Complete Isolation: it provides the highest level of isolation, both in terms of security and resources, eliminating noisy neighbor issues. Easy to segregate responsibilities between teams.</li> <li>Flexibility: Easier to scale and customize for specific tenant requirements without affecting others.</li> <li>Operational Excellence Better lifecycle management - easier changes, less complexity, fewer dependencies due to reduced surface area.</li> <li>Operational Excellence Simple human access model</li> <li>Operational Excellence Simple chargeback/showback model</li> </ul> <p>Cons:</p> <ul> <li>High Costs:  Higher costs due to the need for separate infrastructure for each tenant. Separate clusters cannot efficiently merge different application profiles, which limits their ability to maximize resource utilization.</li> <li>OPerational Overhead: Potential large number of clusters, leading to inefficiencies and higher operational costs.</li> </ul> <p>Considerations:</p> <ul> <li>It can offer superior performance, but managing multiple clusters requires significant operational effort,requiring robust automation and monitoring tools</li> <li>Consider  gitops to automate provsioning/management of multi-clusters</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#resources","title":"Resources","text":"<ol> <li>Multi-tenancy - EKS Best Practices Guides</li> <li>Multi-tenant Design Considerations for Amazon EKS Clusters</li> <li>Three Tenancy Models For Kubernetes</li> <li>Introducing Hierarchical Namespaces</li> <li>Set up soft multi-tenancy with Kiosk on Amazon Elastic Kubernetes Service</li> <li>Configure your cluster for Kubernetes network policies - Amazon EKS</li> <li>Deliver Namespace as a Service multi tenancy for Amazon EKS using Karpenter</li> <li>How to track costs in multi-tenant Amazon EKS clusters using Kubecost</li> <li>Security Practices for MultiTenant SaaS Applications using Amazon EKS</li> </ol>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#discovery-questions","title":"Discovery Questions","text":"<p>Use the discovery questions provided here to help you evaluate your requirements, priorities, and constraints, ensuring you make a future-proof architectural decision.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#general","title":"General","text":"<ul> <li>How many tenants do you anticipate managing within your Kubernetes environment?</li> <li>What future changes or expansions do you anticipate that might impact your Kubernetes strategy.</li> <li>Which of the business drivers (Operational Excellence, Security, Performance, Cost Management, Reliability) is your top priority, and why?</li> <li>Are there any specific technical constraints or legacy systems that need to be integrated with the new Kubernetes setup?</li> <li>What is your timeline for deploying a multi-tenant Kubernetes environment?</li> <li>What is the current skill level of your team in managing Kubernetes and related technologies?</li> <li>Do you have any plans for training or engaging 3rd party to fill skill gaps?</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#operational-excellence","title":"Operational Excellence","text":"<ul> <li>How do you currently manage and maintain your Kubernetes clusters? What challenges are you facing?</li> <li>What level of automation and monitoring do you have in place for your Kubernetes infrastructure?</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#security","title":"Security","text":"<ul> <li>What are your specific security requirements for isolating tenants in a multi-tenant environment? How critical is strong isolation between tenants to your business?</li> <li>What is your approach to configuring Kubernetes RBAC and network policies to ensure tenant security?</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#performance","title":"Performance","text":"<ul> <li>How do you plan to handle potential resource contention between tenants?</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#cost-management","title":"Cost Management","text":"<ul> <li>How do you track and allocate costs to different tenants or projects?</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10002-MULTI-TENANCY/#reliability","title":"Reliability","text":"<ul> <li>What are your uptime and availability requirements for your Kubernetes clusters?</li> <li>How do you plan to ensure resilience and high availability for your tenants?</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/","title":"Multi-Account Strategy","text":"<p>Designing a Kubernetes architecture within AWS involves deciding between deploying clusters in a single AWS account or adopting a multi-account architecture. Each approach has its advantages and disadvantages, and the best choice depends on an organization's specific needs regarding security, isolation, scalability, cost management, and operational complexity.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#decision-drivers","title":"Decision Drivers","text":"<ul> <li>Simplicity</li> <li>Security</li> <li>Scalability</li> <li>Cost Management</li> <li>Operational Complexity</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#considered-options","title":"Considered Options","text":"<ul> <li>Single Account</li> <li>Multi-Account</li> <li>Hybrid</li> <li>Multi-Account with VPC Sharing</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#pros-and-cons-of-the-options","title":"Pros and Cons of the Options","text":""},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#option-1-single-account","title":"Option-1: Single Account","text":"<p>The Single Account option for hosting Kubernetes clusters in AWS represents a straightforward approach to infrastructure management.</p> <p>Advantages</p> <ol> <li> <p>Simplicity: Having all Kubernetes clusters and resources in one AWS account simplifies the setup, management, and operational processes. It makes it easier for teams to deploy applications and manage resources without dealing with the complexities of cross-account permissions and networking.</p> </li> <li> <p>Cost Management: With a single account, tracking and managing costs becomes more straightforward. AWS billing and cost management tools provide a consolidated view of expenses, making it easier to monitor and optimize resource usage across all Kubernetes clusters.</p> </li> <li>Easier Access Management: Managing IAM roles, policies, and permissions can be more straightforward in a single account setup. There's no need to configure cross-account access or deal with the intricacies of assuming roles across accounts. Disadvantages</li> <li>Limited Isolation: A single AWS account provides limited isolation between different environments (e.g., development, staging, production). This could lead to security risks, such as accidental access to or impact on production resources.</li> <li>Blast Radius: In the context of security and operational stability, a single account increases the \"blast radius\" of potential issues. A misconfiguration or security breach in one part of the account can affect all resources, increasing the risk of widespread impact.</li> <li>Resource Limits: AWS imposes certain service limits on the resources that can be created or used within an account. Operating all Kubernetes clusters within a single account could lead to hitting these limits, potentially impacting the ability to scale or deploy new resources as needed.</li> </ol> <p>In summary, while the Single Account option offers simplicity and ease of management, it does come with significant trade-offs in terms of security, isolation, and scalability. This approach might be suitable for smaller organizations or projects with less stringent requirements for isolation between environments. However, for larger enterprises or applications with high demands for security and operational separation, alternative strategies such as multi-account, hybrid, or multi-account with VPC sharing might be more appropriate.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#option-2-multi-account","title":"Option-2: Multi-Account","text":"<p>The Multi-Account option for hosting Kubernetes clusters in AWS leverages multiple AWS accounts to segregate resources, environments, and responsibilities. This approach is geared towards enhancing security, scalability, and organizational flexibility.</p> <p>Advantages</p> <ol> <li> <p>Enhanced Security and Isolation: By segregating resources across multiple accounts, organizations can achieve better isolation between different environments (e.g. development, staging, production). This limits the blast radius in case of security breaches or misconfigurations, as the impact is confined to a single account.</p> </li> <li> <p>Scalability: Using multiple accounts allows organizations to bypass the service limits associated with a single AWS account. Each account has its own set of limits, enabling more extensive and scalable deployments without running into resource constraints.</p> </li> <li>Improved Cost Tracking and Accountability: With resources and environments segregated by account, it becomes easier to track and allocate costs accurately. This aids in financial governance and accountability, as expenses can be directly associated with specific teams, projects, or environments.</li> <li>Regulatory Compliance and Data Privacy: Multi-account structures can facilitate compliance with regulatory requirements by ensuring that data and resources subject to specific regulations are isolated in dedicated accounts. Disadvantages</li> <li>Increased Complexity: Managing multiple AWS accounts adds complexity to network architecture, security configurations, and access management. Organizations need to invest in tools and practices to efficiently manage these aspects, such as AWS Organizations and Service Control Policies (SCPs).</li> <li>Operational Overhead: The need to manage cross-account access, billing, and deployments can introduce significant operational overhead. This includes setting up and maintaining trust relationships between accounts and ensuring consistent deployment practices across accounts.</li> <li>Potential for Resource Duplication: In a multi-account setup, certain shared resources (e.g., IAM roles, VPCs) may need to be replicated across accounts, leading to increased costs and management overhead.</li> </ol> <p>In summary, the Multi-Account option offers substantial benefits in terms of security, scalability, and cost management, making it a compelling choice for medium to large organizations with complex needs. However, the increased complexity and operational overhead require careful planning, automation, and the use of AWS management tools to manage effectively. This approach is particularly well-suited for organizations that prioritize security and isolation between different operational environments or need to adhere to stringent regulatory requirements.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#option-3-hybrid","title":"Option-3: Hybrid","text":"<p>The Hybrid option for hosting Kubernetes clusters in AWS blends the simplicity of a single AWS account with the isolation and scalability benefits of a multi-account architecture. This approach aims to strike a balance between operational efficiency and the need for environmental separation.</p> <p>Advantages</p> <ol> <li>Balanced Isolation and Efficiency: The hybrid model allows critical or shared services to be centralized in a single account (e.g., logging, monitoring, CI/CD pipelines) while segregating environments (development, staging, production) across different accounts. This setup provides a level of isolation for sensitive or critical environments, reducing the blast radius of potential issues, while still maintaining operational efficiency for shared services.</li> <li>Flexibility and Scalability: By using multiple accounts for different stages or projects, organizations can scale more efficiently, avoiding service limits associated with single-account setups. At the same time, the central management of shared services prevents unnecessary duplication of these resources across accounts, optimizing costs and management efforts.</li> <li>Improved Cost Allocation and Visibility: A hybrid approach facilitates detailed cost tracking for projects or environments within their respective accounts, while centralized services maintain simplified billing management. This dual approach can enhance visibility into resource utilization and cost efficiency. Disadvantages</li> <li>Complexity in Management: While aiming to combine the best of both worlds, the hybrid model introduces complexity, particularly in managing access and networking between the centralized services account and the individual environment accounts. Organizations need to carefully plan and implement access controls and networking strategies to ensure smooth operations.</li> <li>Operational Overhead: The need to manage both centralized and distributed components across multiple accounts can increase the operational overhead, requiring more sophisticated governance and automation tools to maintain consistency and efficiency.</li> <li>Potential for Inconsistent Policies: There's a risk of creating inconsistencies in security policies and configurations between the centralized services and the segregated environments. Ensuring uniform security postures and compliance across all accounts requires diligent management and automation.</li> </ol> <p>In summary, the Hybrid option provides a pragmatic approach for organizations looking to balance operational simplicity with the benefits of environmental isolation and scalability. It's particularly suited for organizations that have mature cloud practices and can manage the inherent complexity of navigating between centralized and distributed resources. This model offers flexibility to adapt to different project needs, regulatory requirements, and scalability demands, making it an attractive choice for organizations with diverse portfolios and operational models.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#option-4-multi-account-with-vpc-sharing","title":"Option-4: Multi-Account with VPC Sharing","text":"<p>The Multi-Account with VPC Sharing option for hosting Kubernetes clusters in AWS utilizes AWS's Virtual Private Cloud (VPC) sharing capabilities to offer an advanced solution that combines the isolation benefits of a multi-account strategy with efficient use of network resources. This approach is designed to maximize security, scalability, and cost efficiency by allowing multiple AWS accounts to securely share a single VPC.</p> <p>Advantages</p> <ol> <li>Efficient Resource Utilization: VPC sharing allows for the efficient use of network resources across multiple accounts without the need to replicate network infrastructure. This can lead to cost savings on networking resources and simplifies network management by reducing the number of VPCs and associated components like NAT Gateways and Route Tables.</li> <li>Enhanced Security and Isolation: While sharing the underlying VPC, each account can maintain its security posture. Resources deployed by different accounts within the shared VPC are isolated at the account level, ensuring that the actions of one account do not impact the resources of another. This setup maintains the principle of least privilege and enhances security.</li> <li>Scalability Across Accounts: By leveraging VPC sharing, organizations can scale their operations across multiple accounts without being constrained by VPC resource limitations or the administrative overhead of managing separate VPCs for each account. This facilitates a scalable and flexible architecture that can grow with the organization's needs.</li> <li>Simplified Inter-Account Communication: VPC sharing simplifies the setup of inter-account communication within the shared VPC, reducing the complexity and overhead associated with setting up VPC peering or transit gateways between multiple VPCs in different accounts. Disadvantages</li> <li>Complex Setup and Management: While VPC sharing can reduce the complexity of network management, the initial setup, and ongoing management of permissions, resource sharing, and security configurations require careful planning and understanding of AWS networking and access controls.</li> <li>Potential for Resource Contention: If not properly managed, there could be potential for resource contention within the shared VPC, such as IP address exhaustion or conflicts in resource tagging and naming conventions. Organizations must implement robust governance and monitoring to prevent these issues.</li> <li>Cross-Account Dependency: The shared VPC creates a dependency between accounts, where changes in the shared network infrastructure could impact all accounts. This requires strong change management practices and communication between teams to ensure stability.</li> </ol> <p>In summary, the Multi-Account with VPC Sharing option offers a sophisticated approach to Kubernetes architecture in AWS, providing efficient use of network resources while maintaining the security and isolation benefits of a multi-account setup. This model is particularly well-suited for organizations with advanced cloud infrastructure needs, looking for scalable, secure, and cost-effective solutions. However, it demands a high level of expertise in AWS networking and account management to navigate its complexities successfully.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#related-adrs","title":"Related ADRs","text":""},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#resources","title":"Resources","text":"<p>EKS Best Practice Guide - Multi Account Strategy</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#discovery-questions","title":"Discovery Questions","text":"<p>Deciding on the right Kubernetes architecture in AWS\u2014whether to use a single account, multi-account, hybrid, or multi-account with VPC sharing\u2014requires careful consideration of your organization's specific needs, capabilities, and long-term objectives.</p> <p>Here are key questions that can help guide in making this decision:</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#organizational-structure-and-governance","title":"Organizational Structure and Governance","text":"<ol> <li>How is your organization structured? Understanding whether your organization operates more centrally or if teams work independently can influence whether a single account or a multi-account architecture is more suitable.</li> <li>What are your governance and compliance requirements? If you have strict regulatory compliance needs, a multi-account strategy might offer better isolation and control to meet those requirements.</li> </ol>"},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#security-and-isolation","title":"Security and Isolation","text":"<ol> <li>What level of isolation is required between different environments or projects? If you need strong isolation between production, staging, and development environments to reduce the risk of accidental changes or breaches, a multi-account or hybrid approach may be preferable.</li> <li>How critical are security and the potential blast radius of issues to your organization? Assessing the security implications can help determine the need for separation between resources and environments.</li> </ol>"},{"location":"EKS/Security/ADR-EKS-SEC-10011-MULTI-ACCOUNT-STRATEGY/#scalability-and-flexibility","title":"Scalability and Flexibility","text":"<ol> <li>What are your scalability requirements? Consider whether your infrastructure needs to scale rapidly, and if account-specific service limits might hinder this scalability.</li> <li>Do you require flexibility in resource allocation and cost management across different teams or projects? This can determine whether a multi-account setup, which allows for more granular control and tracking, is necessary.</li> </ol>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/","title":"Store and make sensitive data avaiable","text":"<p>Containers provided a way to standardize application packages that can be deployed across different environments and hardware. However, sensitive data such as passwords to access external resources (such as database) by the application container is not recommended to be stored in the container to reduce attack surface. And different environments probably have different values for the sensitive data (such as passwords for test environment is different than production), keeping this data outside of container image makes them more portable.</p> <p>Kubernetes provides Secrets object type to hold such data and inject into application containers, however these resources are Base64 encoded  and not encrypted. Kubernetes provides ways to secure the secrets such as:</p> <ul> <li> <p>Kubernetes distributes secrets to nodes running Pods that need it and not all nodes.</p> </li> <li> <p>When secrets is available on nodes, they are stored in memory in a tmpfs and never written to physical storage, and Kubernetes remove them when the Pod is no longer available on the node</p> </li> <li> <p>Etcd could be encrypted where it stores the Secrets information. Envelope encryption provides a way to encrypt Kubernetes secrets using CMK.</p> </li> </ul> <p>This document captures different ways on how application containers can consume sensitive data such as database password, private keys, and api keys.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#considered-options","title":"Considered Options","text":"<p>Option 1:  Use Kubernetes CSI driver to load data from sensitive data Store </p> <p>Option 2:  Encrypt and Store sensitive data in Git and load and decrypt them via Kubernetes controller such as SealedSecrets </p> <p>Option 3:  Application to load sensitive data from external store directly </p> <p>Option 4: Use vendor/OSS provided tool like sidecar to load sensitive information such as HAshiCorp and/or External Secrets Operator</p> <p>Option 5: Use Kubernetes native Secrets</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#pros-and-cons-of-the-options","title":"Pros and Cons of the Options","text":""},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#option-1-use-kubernetes-csi-driver-to-load-data-from-sensitive-data-store","title":"Option 1: Use Kubernetes CSI driver to load data from sensitive data Store","text":"<p>Store sensitive data in an external store such as AWS Secrets Manager. So your sensitive data is outside your Kubernetes cluster.  </p> <p>Then use the relevant Kubernetes CSI driver to read the sensitive data from the external store and load/mount onto the application container at runtime as a file. The Kubernetes CSI driver option provides flexibility to access different third-party Secrets store and not just as AWS Secrets Manager.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#pros","title":"Pros","text":"<ul> <li> <p>Avoid storing sensitive data into Kubernetes objects such as secrets. CSI driver mount the sensitive data as files.</p> </li> <li> <p>No change in application is required to to read sensitive data from a central store. Application load data from local files.</p> </li> <li> <p>Existing GitOps principle could be utilized to approve and audit the use of sensitive data through the use of SecretProviderClass CRD object.  </p> </li> <li> <p>easy to migrate to a different backend that also provides industry standard CSI interface</p> </li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#cons","title":"Cons","text":"<ul> <li> <p>Storing sensitive data outside of the cluster will add additional dependency which may hurt the availability of the application if Secret store is not operational.</p> </li> <li> <p>Additional complexity of running a CSI provider in the Kubernetes cluster</p> </li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#option-2-encrypt-and-store-sensitive-data-in-git-and-load-and-decrypt-them-via-kubernetes-controller-such-as-sealedsecrets","title":"Option 2: Encrypt and Store sensitive data in Git and load and decrypt them via Kubernetes controller such as SealedSecrets","text":"<p>Store sensitive data as encrypted objects in the cluster and a Kubernetes controller decrypts and create Secret objects. The encrypted objects such as SealedSecrets has the encrypted data, and a controller creates the Kubernetes Secrets with the un-encrypted data.</p> <p>Teams adopting GitOps can create the encrypted SealedSecrets objects and store them in Git. The controller will decrypt and load them as Kubernetes Secrets. The deployment will refer then secrets to be available at runtime for the applications. </p> <p>For SealedSecrets, although the controler decrypts the information, the encryption is done outside of cluster using the tooling provided by SealedSecrets project. </p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#pros_1","title":"Pros","text":"<ul> <li> <p>The team utilities the existing (if any) GitOps principles</p> </li> <li> <p>No change in application is required to to read sensitive data from Git Repo.</p> </li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#cons_1","title":"Cons","text":"<ul> <li> <p>Other users of namespace can escalate to access the Secrets that is mounted by the controller. </p> </li> <li> <p>Secrets are not the most secure option. As the information will still be available in the cluster as Secrets which will increase the attack surface area</p> </li> <li> <p>Additional complexity of running a Secrets provider in the cluster</p> </li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#option-3-application-to-load-sensitive-data-from-external-store-directly","title":"Option 3: Application to load sensitive data from external store directly","text":"<p>Change application to load and decode encrypted information within the application itself from the exernal store.</p> <p>Using this approach the application will use the sensitive data provider API to interact and load the data onto application memory.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#pros_2","title":"Pros","text":"<ul> <li> <p>Direct coupling may help to use more features provided by the external store vendor</p> </li> <li> <p>More secure approach as sensitive data resides in memory of the application container</p> </li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#cons_2","title":"Cons","text":"<ul> <li> <p>This option will result in changes in multiple applications which result in more maintenance and difficult to change providers.</p> </li> <li> <p>High cost if you want to move to another vendor</p> </li> <li> <p>Couples the application logic with configuration security. </p> </li> <li> <p>generally anti pattern https://12factor.net/config</p> </li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#option-4-use-vendoross-provided-tool-to-load-sensitive-information-such-as-hashicorp-vault-sidecar-or-external-secrets-operator","title":"Option 4: Use vendor/OSS provided tool to load sensitive information such as HashiCorp Vault sidecar or External Secrets Operator","text":"<p>Some external sensitive data stores such as Hashicorp Vault, provide an sidecar container that can be associated with your application. The container works as a bridge for what data is needed by the application container and how to get it from the external store. This is implemented as a  mutating webhook, that allows modification of any resource when it is created through intercepting Kubernetes API calls. When a Pod specification contains a vault-specific annotation, the  controller will add a container for syncing with Vault and to mount a volume for the secret data onto the application container.</p> <p>You can use other provider such as External Secrets Operator which integrates with an dedicated secret store such as AWS Secrets Manager which can perform the encryption.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#pros_3","title":"Pros","text":"<ul> <li>No change in application is required to to read sensitive data from a central store.</li> <li>Direct coupling may help to use more features provided by the external store vendor</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#cons_3","title":"Cons","text":"<ul> <li>Tight coupling between the vendor provided container may result in lock-in</li> <li>High cost if you want to move to another vendor</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#resources","title":"Resources","text":"<p>EKS Best practices.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#discovery-questions","title":"Discovery Questions","text":"<p>This section aims to provide multiple perspectives of this decision and how you assess the right fit for your use case. </p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#general-questions","title":"General questions","text":"<p>The section provide additional considerations that may be useful for adopting a particular solution. Howver, this ADR will not provide any recommendations for these considetaions.</p> <ul> <li> <p>Do you have an enterprise standard in your org to manage Secret? How will it add to complexity if you are not consistent with your enpterprise standard and what features your existing solution may not provide?</p> </li> <li> <p>Is your secret management solution subject to any internal or external regulatory requirements standards?</p> </li> <li> <p>Do you have an centralised team to manage sensitive data? How your decision will effect the process of sensitive data management? </p> </li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#whats-the-impact-if-the-sensitive-data-is-compromised","title":"What\u2019s the impact if the sensitive data is compromised?","text":"<p>This document does not deal with if the sensitive data store in compromised. However, if one or a list od secrets are compromised, immediately rotate them. It is therefore important to select a sensitive data provider that supports rotation and have a routine rotation policy implemented. </p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#do-you-use-an-existing-sensitive-data-provider-as-part-of-your-enterprise","title":"Do you use an existing sensitive data provider as part of your enterprise?","text":"<p>If you want to continue with your Enterprise standards, Kubernetes CSI Driver and External Secrets Operator may provided integration with your existing sensitive data provider. </p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#what-are-the-security-and-compliance-requirements-for-storing-and-accessing-the-sensitive-data-eg-encryption-at-rest-access-control-auditing-monitor-rotation","title":"What are the security and compliance requirements for storing and accessing the sensitive data (e.g., encryption at rest, access control, auditing, monitor, rotation)?","text":"<p>Managing sensitive data lifecycle is a specialized task. Adopting dedicated stores such as AWS Secrets Manager would result in reducing the complexity of your architecture. These stores provides observability, access control and lifecycle of your sensitive data.  Use Kubernetes components with audit trails to load and make these data available to your applications Kubernetes CSI driver and external secrets operator options provide integration with state of the art external sensitive data stores and could be considered</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#do-you-want-to-decouple-the-configuration-security-concerns-from-the-application-logic","title":"Do you want to decouple the configuration security concerns from the application logic?","text":"<p>It is recommended to avoid making your application aware of sensitive data location. Application shall load the sensitive data using standard approaches such as files mounted on the container volume. All options other than the \u201cchange application to load data directly from sensitive data store\u201d provide this option and could be a good fit.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#do-you-want-to-use-open-solution-for-better-flexibility-and-not-relying-on-3rd-party-support","title":"Do you want to use open solution for better flexibility and not relying on 3rd party support?","text":"<p>Kubernetes CSI driver, External Secrets Operator provide use standard Kubernetes constructs such as controllers and support for a variety of external sensitive data stores with source code available openly. SealedSecrets also falls into this category with the sensitive data stored in Git.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10012-Sensitive-Data/#how-important-is-the-availability-of-the-sensitive-data-provider-to-your-applications-functionality-can-your-application-gracefully-handle-temporary-unavailability-of-the-sensitive-data-provider","title":"How important is the availability of the sensitive data provider to your application's functionality? Can your application gracefully handle temporary unavailability of the sensitive data provider?","text":"<p>Since loading data onto the applications via external sensitive data store requires access to the secrets store. It\u2019s availability may reduce your application resilience because your application may fail to start new instances if the store is not available. In this case loading secrets onto your Kubernetes cluster would makes more sense. Do note that cloud based sensitive data provider such as KMS has a very high SLA.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10015-HOST-OS/","title":"Chose a host OS for your EKS worker nodes","text":"<p>Deciding on the right host image for EKS worker nodes is crucial to optimizing performance, security, and operational excellence based on an organization's specific needs. The host image provides the base operating system and runtime for the nodes.</p>"},{"location":"EKS/Security/ADR-EKS-SEC-10015-HOST-OS/#decision-drivers","title":"Decision Drivers","text":"<ul> <li>Security - Ability to harden and control the host environment </li> <li>Performance - Optimized for running containers and Kubernetes </li> <li>Operational Excellence - Reliability, automation, and ease of management </li> <li>Benefits - Balancing benefits with operation overhead</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10015-HOST-OS/#considered-options","title":"Considered Options","text":"<ul> <li>Build EKS worker node AMI on Amazon EKS Optimised AMI</li> <li>Build EKS worker node AMI on Organisation Hardened Linux SOE (i.e. RHEL)  </li> <li>Build EKS worker node AMI on Amazon EKS Optimised AMI</li> <li>Bottlerocket</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10015-HOST-OS/#pros-and-cons-of-the-options","title":"Pros and Cons of the Options","text":""},{"location":"EKS/Security/ADR-EKS-SEC-10015-HOST-OS/#build-eks-worker-node-ami-on-amazon-linux-ami","title":"Build EKS worker node AMI on Amazon Linux AMI","text":"<p>Amazon Linux is a general purpose OS provided by AWS. This is a solution that customer will need to manage the lifecycle of building EKS worker node AMI based on Amazon Linux AMI. They could refer to the open source Amazon Optimized EKS AMI on what packages to be installed. [1]</p> <ul> <li>Good, Customers have full control on the lifecycle of the worker node AMIs, which could meet their organisation SLAs</li> <li>Good, leverage some built-in benefits included in Amazon Linux such as acclerated instance support </li> <li>Bad, because lacks EKS specific optimizations</li> <li>Bad, remarkable effort is required to build and manage the worker node AMI lifecycle.</li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10015-HOST-OS/#organisation-hardened-linux-soe-ie-rhel","title":"Organisation Hardened Linux SOE (i.e. RHEL)","text":"<p>This is a solution that customer will need to manage the lifecycle of building EKS worker node AMI based on their organisational Hardened Linux SOE They could refer to the open source Amazon Optimized EKS AMI on what packages to be installed. [2]</p> <ul> <li>Good, because provides full flexibility to customize to unique needs</li> <li>Good, Customers have full control on the lifecycle of the worker node AMIs, which could meet their organisation SLAs.</li> <li>Bad, because lacks EKS specific optimizations</li> <li>Bad, Significant effort is required to build and manage the worker node AMI lifecycle. </li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10015-HOST-OS/#amazon-eks-optimised-ami","title":"Amazon EKS Optimised AMI","text":"<p>This is a solution that customer will need to manage the lifecycle of building EKS worker node AMI based on Amazon EKS Optimised AMI. [3]</p> <ul> <li>Good, because it is purpose-built by AWS for EKS performance and security </li> <li>Good, leverage some built-in benefits included in Amazon Linux such as acclerated instance support </li> <li>Good, leverage </li> <li>Neutral, because relies on AWS to release the base image  </li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10015-HOST-OS/#bottlerocket-aws-managed-minimal-os-for-containers","title":"Bottlerocket - AWS managed minimal OS for containers","text":"<p>Bottlerocket is a dedicated Linux OS for running containers, managed by AWS.</p> <ul> <li>Good, because optimized specifically for container workloads </li> <li>Good, Reduces the effort to manage additional packages since it has been pre-tested by AWS to work with EKS.</li> <li>Good, Reduce container startup time on Amazon EKS with Bottlerocket data volume</li> <li>Neutral, because limited flexibility as a minimal OS  </li> <li>Bad, because may not support running third-party agents </li> </ul>"},{"location":"EKS/Security/ADR-EKS-SEC-10015-HOST-OS/#resources","title":"Resources","text":"<ol> <li> <p>Amazon EKS AMI Build Specification</p> </li> <li> <p>Amazon EKS AMI RHEL Build Specification</p> </li> <li> <p>Amazon EKS Custom AMIs</p> </li> <li> <p>Amazon EKS Now Supports Bottlerocket</p> </li> <li> <p>AWS Bottlerocket </p> </li> <li> <p>Amazon Linux Security Center</p> </li> <li> <p>Amazon EKS Optimized AMI releases</p> </li> <li> <p>Reduce container startup time on Amazon EKS with Bottlerocket data volume</p> </li> </ol>"},{"location":"EKS/Security/ADR-EKS-SEC-10015-HOST-OS/#discovery-questions","title":"Discovery Questions","text":"<ol> <li> <p>How much effort are you able to dedicate to hardening and optimizing a custom host image? The less effort available, the more a managed image like Bottlerocket may be preferred.</p> </li> <li> <p>Do you have any unique requirements or dependencies that would require a customized or full Linux distribution like Ubuntu or RHEL? </p> </li> <li> <p>Are there any regulatory compliance or security certifications you need to adhere to that may constrain the host image?</p> </li> <li> <p>What level of performance and low latency is needed for your containerized applications? Any specific requrement of start time of conatiner if you image size is very big. </p> </li> <li> <p>Do you need to run third-party agents or software outside of containers on the host? This may rule out minimal OS options.  </p> </li> <li> <p>Do you expect to need to frequently SSH into worker nodes for troubleshooting or maintenance?</p> </li> <li> <p>Do you want the OS managed fully by AWS or require more customization control?</p> </li> </ol>"},{"location":"Others/CODE_OF_CONDUCT/","title":"CODE OF CONDUCT","text":""},{"location":"Others/CODE_OF_CONDUCT/#code-of-conduct","title":"Code of Conduct","text":"<p>This project has adopted the Amazon Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.</p>"},{"location":"Others/CONTRIBUTING/","title":"Contributing Guidelines","text":"<p>Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community.</p> <p>Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.</p>"},{"location":"Others/CONTRIBUTING/#reporting-bugsfeature-requests","title":"Reporting Bugs/Feature Requests","text":"<p>We welcome you to use the GitHub issue tracker to report bugs or suggest features.</p> <p>When filing an issue, please check existing open, or recently closed, issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful:</p> <ul> <li>A reproducible test case or series of steps</li> <li>The version of our code being used</li> <li>Any modifications you've made relevant to the bug</li> <li>Anything unusual about your environment or deployment</li> </ul>"},{"location":"Others/CONTRIBUTING/#contributing-via-pull-requests","title":"Contributing via Pull Requests","text":"<p>Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that:</p> <ol> <li>You are working against the latest source on the main branch.</li> <li>You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already.</li> <li>You open an issue to discuss any significant work - we would hate for your time to be wasted.</li> </ol> <p>To send us a pull request, please:</p> <ol> <li>Fork the repository.</li> <li>Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change.</li> <li>Ensure local tests pass.</li> <li>Commit to your fork using clear commit messages.</li> <li>Send us a pull request, answering any default questions in the pull request interface.</li> <li>Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation.</li> </ol> <p>GitHub provides additional document on forking a repository and creating a pull request.</p>"},{"location":"Others/CONTRIBUTING/#finding-contributions-to-work-on","title":"Finding contributions to work on","text":"<p>Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels (enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.</p>"},{"location":"Others/CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>This project has adopted the Amazon Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.</p>"},{"location":"Others/CONTRIBUTING/#security-issue-notifications","title":"Security issue notifications","text":"<p>If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page. Please do not create a public github issue.</p>"},{"location":"Others/CONTRIBUTING/#licensing","title":"Licensing","text":"<p>See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution.</p>"},{"location":"Others/LICENSE/","title":"LICENSE","text":"<p>MIT No Attribution</p> <p>Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"}]}